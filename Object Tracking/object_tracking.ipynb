{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["LM0UdBsUQlIP","h0_ArXTX8mRM","5mq7V6Do7JeU","sAxPU6YmLdFg","FJIyYSxtrXaI","zf7IgIOdizlP","uTIFmLEJ82mS","JeS-4QjCm9tH","iT2iibsMnLKz","EwzK_TKAi9hz","uA3Ld7r4rrgU","bh0qSG-SllU-","ZJuNq333Y6Bm","U8yVwBe4Y9Q0","LVG8AUa-ZKeU","4uB-nmqFZO1K","Ko_zaI7xZSLQ"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["**Name: Faiz Andrea Ganz**\n","\n","**NetID: fag277**"],"metadata":{"id":"viJDdBYW9q43"}},{"cell_type":"markdown","source":["## Introduction\n","\n","For the following project we are going to build an object tracker with the help of an image detector (neural network) and the use of a 2D Kalman filter. The tracker is going to be used on two separate videos. In the first video, a ball rolls from the right to the left of the screen and passes behind a white sheet of paper. In the second video there are two balls which start from opposite ends of the screen and cross each other in the middle. Hence at one point, one of the balls is occluded by the other.\n","\n","The object detector only help us find the instances of the objects when they appear in the image. Hence, to help us track the balls while occluded, we need to use probabilistic reasoning, this being a recursive state estimation problem, where our variables of interest are motion quantities in the object (position, velocity, and acceleration). The Kalman filter proves to be a good solution for this problem. We build a Kalman filter for each object we want to track and update it with the detected position. Whenever the object is occluded or simply not detected, the Kalman filter will instead provide the trajectory of object, by using the next state prediction calculated on the last detected point. The next state prediciton is then used to update the Kalman filter, since there is no detected input.\n","\n","Because there are two balls in the second video, we need to keep track of the two instances separately, as the object detector does not tell us which instance is which. To do so, we update the centroids of each instance by selecting the one with the shortest euclidian distance to the predicted coordinates for this time step.\n","\n","Disclaimer: The implementation uses some simplifies functionality. The trackers do initialize objects dynamically and for the second video the kalman filters and position of the two object were declared before hand for simplicity. Links to referenced sources are included at the beginning of cells.\n","\n","The result frames for the videos are contained in the results folder."],"metadata":{"id":"kd4KKLTS9i9W"}},{"cell_type":"markdown","source":["## Setup"],"metadata":{"id":"LM0UdBsUQlIP"}},{"cell_type":"markdown","source":["#### Mount Drive and Change Directory"],"metadata":{"id":"h0_ArXTX8mRM"}},{"cell_type":"code","source":["import sys\n","from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"id":"moXTmCit-JsL","colab":{"base_uri":"https://localhost:8080/","height":353},"executionInfo":{"status":"error","timestamp":1670091875367,"user_tz":300,"elapsed":2462,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}},"outputId":"b1c7d8ba-8a87-47ab-b5f2-300fc52727ac"},"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d8c218c276d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/ai/hw3/"],"metadata":{"id":"G6NZOsay8p9J","executionInfo":{"status":"aborted","timestamp":1670091875368,"user_tz":300,"elapsed":4,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"Thu3dULopwVv","executionInfo":{"status":"aborted","timestamp":1670091875368,"user_tz":300,"elapsed":4,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Installing Packages and ImageAI\n","\n","For the following project, we will use the ImageAI library and import a Retina (ResNet50 backbone) based object detection model to detect the instances of the objects in each frame."],"metadata":{"id":"5mq7V6Do7JeU"}},{"cell_type":"code","source":["!pip install tensorflow-gpu==2.4.0\n","!pip3 install scipy\n","!pip3 install opencv-python\n","!pip3 install pillow\n","!pip3 install h5py\n","!pip3 install keras"],"metadata":{"id":"PB33-to7t-Kj","executionInfo":{"status":"aborted","timestamp":1670091875368,"user_tz":300,"elapsed":4,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install imageai --upgrade"],"metadata":{"id":"HeiqhTq9vK3P","executionInfo":{"status":"aborted","timestamp":1670091875368,"user_tz":300,"elapsed":4,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Load Detector Model form ImageAI\n","\n","For the model we chose the pretrained weights obtained from training over the COCO dataset, which contains an object class \"sports ball\"."],"metadata":{"id":"sAxPU6YmLdFg"}},{"cell_type":"code","source":["from imageai.Detection import ObjectDetection\n","\n","detector = ObjectDetection()\n","detector.setModelTypeAsRetinaNet()\n","detector.setModelPath(\"resnet50_coco_best_v2.1.0.h5\")\n","detector.loadModel()"],"metadata":{"id":"DP9ReuCBpyDu","executionInfo":{"status":"aborted","timestamp":1670091875369,"user_tz":300,"elapsed":5,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Reading Frames"],"metadata":{"id":"FJIyYSxtrXaI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrYCrXU1omw6","executionInfo":{"status":"aborted","timestamp":1670091875369,"user_tz":300,"elapsed":5,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"outputs":[],"source":["import cv2\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import os"]},{"cell_type":"markdown","source":["Using the open-cv library we read the video frames and save them as images. For sake of simplicity and debugging, we save resulting images at intermediate steps and load them again for the next step, although everything can be done in one single loop."],"metadata":{"id":"p6mFD0i4PbV6"}},{"cell_type":"code","source":["def FrameCapture(path, folder): # https://www.geeksforgeeks.org/python-program-extract-frames-using-opencv/\n","    vidObj = cv2.VideoCapture(path)\n","    count = 0\n","    success = 1\n","    while success:\n","        success, image = vidObj.read()\n","        if success:\n","            cv2.imwrite(folder + \"frame%d.jpg\" % count, image)\n","            count += 1\n","    return count"],"metadata":{"id":"dE66auuh8L-C","executionInfo":{"status":"aborted","timestamp":1670091875369,"user_tz":300,"elapsed":5,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Kalman Filter 2D Class"],"metadata":{"id":"zf7IgIOdizlP"}},{"cell_type":"code","source":["class KalmanFilter(object): # https://machinelearningspace.com/2d-object-tracking-using-kalman-filter/\n","    def __init__(self, dt, u_x,u_y, std_acc, x_std_meas, y_std_meas):\n","        \"\"\"\n","        :param dt: sampling time (time for 1 cycle)\n","        :param u_x: acceleration in x-direction\n","        :param u_y: acceleration in y-direction\n","        :param std_acc: process noise magnitude\n","        :param x_std_meas: standard deviation of the measurement in x-direction\n","        :param y_std_meas: standard deviation of the measurement in y-direction\n","        \"\"\"\n","        # Define sampling time\n","        self.dt = dt\n","        # Define the  control input variables\n","        self.u = np.matrix([[u_x],[u_y]])\n","        # Intial State\n","        self.x = np.matrix([[0], [0], [0], [0]])\n","        # Define the State Transition Matrix A\n","        self.A = np.matrix([[1, 0, self.dt, 0],\n","                            [0, 1, 0, self.dt],\n","                            [0, 0, 1, 0],\n","                            [0, 0, 0, 1]])\n","        # Define the Control Input Matrix B\n","        self.B = np.matrix([[(self.dt**2)/2, 0],\n","                            [0, (self.dt**2)/2],\n","                            [self.dt,0],\n","                            [0,self.dt]])\n","        # Define Measurement Mapping Matrix\n","        self.H = np.matrix([[1, 0, 0, 0],\n","                            [0, 1, 0, 0]])\n","        #Initial Process Noise Covariance\n","        self.Q = np.matrix([[(self.dt**4)/4, 0, (self.dt**3)/2, 0],\n","                            [0, (self.dt**4)/4, 0, (self.dt**3)/2],\n","                            [(self.dt**3)/2, 0, self.dt**2, 0],\n","                            [0, (self.dt**3)/2, 0, self.dt**2]]) * std_acc**2\n","        #Initial Measurement Noise Covariance\n","        self.R = np.matrix([[x_std_meas**2,0],\n","                           [0, y_std_meas**2]])\n","        #Initial Covariance Matrix\n","        self.P = np.eye(self.A.shape[1])\n","\n","    def predict(self):\n","        # Refer to :Eq.(9) and Eq.(10)  in https://machinelearningspace.com/object-tracking-simple-implementation-of-kalman-filter-in-python/?preview_id=1364&preview_nonce=52f6f1262e&preview=true&_thumbnail_id=1795\n","        # Update time state\n","        #x_k =Ax_(k-1) + Bu_(k-1)     Eq.(9)\n","        self.x = np.dot(self.A, self.x) + np.dot(self.B, self.u)\n","        # Calculate error covariance\n","        # P= A*P*A' + Q               Eq.(10)\n","        self.P = np.dot(np.dot(self.A, self.P), self.A.T) + self.Q\n","        return self.x[0:2]\n","\n","    def update(self, z):\n","        # Refer to :Eq.(11), Eq.(12) and Eq.(13)  in https://machinelearningspace.com/object-tracking-simple-implementation-of-kalman-filter-in-python/?preview_id=1364&preview_nonce=52f6f1262e&preview=true&_thumbnail_id=1795\n","        # S = H*P*H'+R\n","        S = np.dot(self.H, np.dot(self.P, self.H.T)) + self.R\n","        # Calculate the Kalman Gain\n","        # K = P * H'* inv(H*P*H'+R)\n","        K = np.dot(np.dot(self.P, self.H.T), np.linalg.inv(S))  #Eq.(11)\n","        self.x = np.round(self.x + np.dot(K, (z - np.dot(self.H, self.x))))   #Eq.(12)\n","        I = np.eye(self.H.shape[1])\n","        # Update error covariance matrix\n","        self.P = (I - (K * self.H)) * self.P   #Eq.(13)\n","        return self.x[0:2]"],"metadata":{"id":"a8xOoOJCi3Y_","executionInfo":{"status":"aborted","timestamp":1670091875369,"user_tz":300,"elapsed":5,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## I. Single Object with Occlusion by another Object"],"metadata":{"id":"uTIFmLEJ82mS"}},{"cell_type":"markdown","source":["### I.a Detect Object in Frames"],"metadata":{"id":"JeS-4QjCm9tH"}},{"cell_type":"code","source":["num_frames = FrameCapture(\"ball.mp4\", \"./data_single/\")"],"metadata":{"id":"ndKZlis489Gl","executionInfo":{"status":"aborted","timestamp":1670091875369,"user_tz":300,"elapsed":4,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = './data_single/'\n","detections = []\n","\n","for i in range(num_frames):\n","    f = os.path.join(directory, 'frame%d.jpg' % i)\n","    if os.path.isfile(f):\n","        detection = detector.detectObjectsFromImage(\n","            input_image=f, \n","            output_image_path=\"./detections_single/out_frame%d.jpg\" % i, \n","            minimum_percentage_probability=10\n","            )\n","        detections += [detection]"],"metadata":{"id":"rx243ZZvF6OW","executionInfo":{"status":"aborted","timestamp":1670091875369,"user_tz":300,"elapsed":3840,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### I.b Track through Occlusion Using Probabilistic Reasoning"],"metadata":{"id":"iT2iibsMnLKz"}},{"cell_type":"markdown","source":["#### Tracking"],"metadata":{"id":"EwzK_TKAi9hz"}},{"cell_type":"code","source":["probabilities = []\n","x_trajectory = []\n","y_trajectory = []\n","x_predictions = []\n","y_predictions = []\n","\n","KF = KalmanFilter(1/30, 0, 0, 0.1, 0.001, 0.001)\n","\n","color = (255, 0, 0)\n","thickness = 2\n","radius = 3\n","\n","for i, detection in enumerate(detections):\n","    f = os.path.join(directory, 'frame%d.jpg' % i)\n","    out_img = cv2.imread(f)\n","    found = False\n","\n","    for obj in detection:\n","        if obj['name'] == 'sports ball' and not found:\n","            x_min, y_min, x_max, y_max = obj['box_points']\n","            x_center = (x_min + x_max) / 2\n","            y_center = (y_min + y_max) / 2\n","            x_trajectory += [x_center]\n","            y_trajectory += [y_center]\n","            probabilities += [obj['percentage_probability']]\n","            center = np.array([[x_center], [y_center]])\n","            (x, y) = KF.predict()\n","            (x1, y1) = KF.update(center)\n","            x_predictions.append(x.item())\n","            y_predictions.append(y.item())\n","            out_img = cv2.rectangle(out_img, (x_min, y_min), (x_max, y_max), color, thickness)\n","            found = True\n","\n","    if not found:\n","        x_trajectory += [-1]\n","        y_trajectory += [-1]\n","        probabilities += [0]\n","        (x, y) = KF.predict()\n","        center = np.array([[int(x)], [int(y)]])\n","        (x1, y1) = KF.update(center)\n","        x_predictions.append(x.item())\n","        y_predictions.append(y.item())\n","        out_img = cv2.rectangle(out_img,\n","                                    (int(x_predictions[-1] - 48), int(y_predictions[-1] - 48)),\n","                                    (int(x_predictions[-1] + 48), int(y_predictions[-1] + 48)),\n","                                    (255, 51, 255),\n","                                    thickness)\n","\n","    for j in range(len(x_trajectory)):\n","        if x_trajectory[j] == -1:\n","            out_img = cv2.circle(out_img, (int(x_predictions[j]), int(y_predictions[j])), radius, (255, 51, 255), thickness)\n","        else:\n","            out_img = cv2.circle(out_img, (int(x_predictions[j]), int(y_predictions[j])), radius, (255, 51, 255), thickness)\n","            out_img = cv2.circle(out_img, (int(x_trajectory[j]), int(y_trajectory[j])), radius, (255, 0, 0), thickness)\n","    \n","    cv2.imwrite(\"./results_single/res_frame%d.jpg\" % i, out_img)"],"metadata":{"id":"ljDfys1OjhrQ","executionInfo":{"status":"aborted","timestamp":1670091875370,"user_tz":300,"elapsed":3841,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(1,3, figsize=(25,5))\n","\n","axs[0].plot(range(len(probabilities)), probabilities)\n","axs[0].set_xlabel('frame')\n","axs[0].set_ylabel('confidence of detection')\n","axs[0].set_title('Detection Confidence')\n","\n","axs[1].plot(range(len(x_trajectory)), x_trajectory, label='detected')\n","axs[1].plot(range(len(x_predictions)), x_predictions, label='Kalman')\n","axs[1].set_xlabel('frame')\n","axs[1].set_ylabel('x-position')\n","axs[1].set_title('Displacement (x)')\n","axs[1].legend()\n","\n","axs[2].plot(range(len(y_trajectory)), y_trajectory, label='detected')\n","axs[2].plot(range(len(y_predictions)), y_predictions, label='Kalman')\n","axs[2].set_xlabel('frame')\n","axs[2].set_ylabel('y-position')\n","axs[2].set_title('Displacement (y)')\n","axs[2].legend()\n","\n","plt.show()"],"metadata":{"id":"rl93x3OT-GtR","executionInfo":{"status":"aborted","timestamp":1670091875370,"user_tz":300,"elapsed":3837,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Video"],"metadata":{"id":"uA3Ld7r4rrgU"}},{"cell_type":"code","source":["# https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-colab\n","frame = cv2.imread(\"./results_single/res_frame0.jpg\")\n","height, width, layers = frame.shape\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","video = cv2.VideoWriter('ball_tracking.mp4', fourcc, 15, (width,height))\n","\n","for i in range(num_frames):\n","    img = cv2.imread(\"./results_single/res_frame%d.jpg\" % i)\n","    video.write(img)\n","    \n","cv2.destroyAllWindows()\n","video.release()"],"metadata":{"id":"zlUqZVhNjv9J","executionInfo":{"status":"aborted","timestamp":1670091875370,"user_tz":300,"elapsed":3836,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## II. Occlusion by the Same Object"],"metadata":{"id":"bh0qSG-SllU-"}},{"cell_type":"markdown","source":["### II.a Detect Object in Frames"],"metadata":{"id":"ZJuNq333Y6Bm"}},{"cell_type":"code","source":["num_frames = FrameCapture(\"objectTracking_examples_multiObject.avi\", \"./data_double/\")"],"metadata":{"id":"8MPYfcWtJUPw","executionInfo":{"status":"aborted","timestamp":1670091875370,"user_tz":300,"elapsed":3835,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = './data_double/'\n","detections = []\n","\n","for i in range(num_frames):\n","    f = os.path.join(directory, 'frame%d.jpg' % i)\n","    if os.path.isfile(f):\n","        detection = detector.detectObjectsFromImage(\n","            input_image=f, \n","            output_image_path=\"./detections_double/out_frame%d.jpg\" % i, \n","            minimum_percentage_probability=12\n","            )\n","        detections += [detection]"],"metadata":{"id":"7fOy4HorXQiv","executionInfo":{"status":"aborted","timestamp":1670091875370,"user_tz":300,"elapsed":3834,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### II.b Track through Occlusion Using Probabilistic Reasoning"],"metadata":{"id":"U8yVwBe4Y9Q0"}},{"cell_type":"markdown","source":["#### Object Tracker Class"],"metadata":{"id":"LVG8AUa-ZKeU"}},{"cell_type":"code","source":["class SportsBall:\n","    def __init__(self, x_hist, y_hist, p_hist, x_pred_hist, y_pred_hist):\n","        self.initialized = True\n","        self.x_trajectory = x_hist\n","        self.y_trajectory = y_hist\n","        self.probabilities = p_hist\n","        self.x_predictions = x_pred_hist\n","        self.y_predictions = y_pred_hist\n","    \n","    def update(self, x_center, y_center, prob, x_pred, y_pred):\n","        self.x_trajectory += [x_center]\n","        self.y_trajectory += [y_center]\n","        self.probabilities += [prob]\n","        self.x_predictions += [x_pred]\n","        self.y_predictions += [y_pred]\n","    \n","    def initialize(self):\n","        self.initialized = True\n","\n","    def get_expected_coordinates(self):\n","        return self.x_predictions[-1], self.y_predictions[-1]"],"metadata":{"id":"wqHyXMsvocX1","executionInfo":{"status":"aborted","timestamp":1670091875370,"user_tz":300,"elapsed":3834,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Tracking"],"metadata":{"id":"4uB-nmqFZO1K"}},{"cell_type":"code","source":["# It would be very hard to build a tracker that initializes the objects and \n","# kalman filters on the spot so I opted to start with assumed, initial values \n","# for the two sports balls\n","\n","filters = [KalmanFilter(1/30, 0, 0, 0.1, 0.001, 0.001),\n","           KalmanFilter(1/30, 0, 0, 0.1, 0.001, 0.001)]\n","\n","filters[0].update(np.array([[622.5], [153.0]]))\n","filters[1].update(np.array([[6.5], [162.5]]))\n","\n","(x1, y1) = filters[0].predict()\n","(x2, y2) = filters[1].predict()\n","\n","objects = [SportsBall(x_hist=[622.5], y_hist=[153.0], p_hist=[],x_pred_hist=[x1], y_pred_hist=[y1]),\n","           SportsBall(x_hist=[6.5], y_hist=[162.5], p_hist=[], x_pred_hist=[x2], y_pred_hist=[y2])]\n","\n","colors = [(255, 0, 0), (0, 0, 255)]\n","pred_colors = [(255, 128, 0), (0, 128, 255)]\n","thickness = 2\n","radius = 5\n","    \n","for i, detection in enumerate(detections):\n","    f = os.path.join(directory, 'frame%d.jpg' % i)\n","    out_img = cv2.imread(f)\n","\n","    boxes = []\n","    probs = []\n","    for obj in detection:\n","        if obj['name'] == 'sports ball':\n","            x_min, y_min, x_max, y_max = obj['box_points']\n","            boxes += [obj['box_points']]\n","            probs += [obj['percentage_probability']]\n","\n","    if len(boxes) == 2:\n","        for j, box in enumerate(boxes):\n","            distances = []\n","            x_min, y_min, x_max, y_max = box\n","            x_center = (x_min + x_max) / 2\n","            y_center = (y_min + y_max) / 2\n","\n","            for ball in objects:\n","                (cx, cy) = ball.get_expected_coordinates()\n","                d = np.sqrt( (x_center - cx)**2 + (y_center - cy)**2)\n","                distances += [d]\n","\n","            obj_idx = np.argmin(distances)\n","            (x1, y1) = filters[obj_idx].update([[x_center], [y_center]])\n","            (x, y) = filters[obj_idx].predict()\n","            objects[obj_idx].update(x_center, y_center, probs[j], x.item(), y.item())\n","            out_img = cv2.rectangle(out_img, (x_min, y_min), (x_max, y_max), colors[obj_idx], thickness)\n","\n","    elif len(boxes) == 1:\n","        for j, box in enumerate(boxes):\n","            distances = []\n","            x_min, y_min, x_max, y_max = box\n","            x_center = (x_min + x_max) / 2\n","            y_center = (y_min + y_max) / 2\n","\n","            for ball in objects:\n","                (cx, cy) = ball.get_expected_coordinates()\n","                d = np.sqrt( (x_center - cx)**2 + (y_center - cy)**2)\n","                distances += [d]\n","                \n","            obj_idx = np.argmin(distances)\n","            (x1, y1) = filters[obj_idx].update([[x_center], [y_center]])\n","            (x, y) = filters[obj_idx].predict()\n","            objects[obj_idx].update(x_center, y_center, probs[j], x.item(), y.item())\n","\n","            missed_idx = 0 if obj_idx == 1 else 1\n","            (oldx, oldy) = objects[missed_idx].get_expected_coordinates()\n","            (x1, y1) = filters[missed_idx].update(np.array([[int(oldx)], [int(oldy)]]))\n","            (x, y) = filters[missed_idx].predict()\n","            objects[missed_idx].update(oldx, oldy, 0, x.item(), y.item())\n","            out_img = cv2.rectangle(out_img, (x_min, y_min), (x_max, y_max), colors[obj_idx], thickness)\n","            out_img = cv2.rectangle(out_img, (int(oldx) - 45, int(oldy) - 45), (int(oldx) + 45, int(oldy) + 45), pred_colors[missed_idx], thickness)\n","\n","    elif len(boxes) == 0:\n","        for j, ball in enumerate(objects):\n","            (oldx, oldy) = objects[j].get_expected_coordinates()\n","            (x1, y1) = filters[j].update(np.array([[int(oldx)], [int(oldy)]]))\n","            (x, y) = filters[j].predict()\n","            ball.update(oldx, oldy, 0, x.item(), y.item())\n","            out_img = cv2.rectangle(out_img, (int(oldx) - 45, int(oldy) - 45), (int(oldx) + 45, int(oldy) + 45), colors[j], thickness)\n","    \n","    # # Plot Entire Trajectory\n","    # for j, ball in enumerate(objects):\n","    #     for k in range(len(ball.x_trajectory[1:])):\n","    #         if ball.probabilities[k] == 0:\n","    #             out_img = cv2.circle(out_img, (int(ball.x_predictions[k]), int(ball.y_predictions[k])), radius, pred_colors[j], thickness)\n","    #         else:\n","    #             out_img = cv2.circle(out_img, (int(ball.x_trajectory[k+1]), int(ball.y_trajectory[k+1])), radius, colors[j], thickness)\n","    #             out_img = cv2.circle(out_img, (int(ball.x_predictions[k]), int(ball.y_predictions[k])), radius, pred_colors[j], thickness)\n","\n","    for j, ball in enumerate(objects):\n","        if ball.probabilities[-1] == 0:\n","            out_img = cv2.circle(out_img, (int(ball.x_predictions[-2]), int(ball.y_predictions[-2])), radius, pred_colors[j], thickness)\n","        else:\n","            out_img = cv2.circle(out_img, (int(ball.x_predictions[-2]), int(ball.y_predictions[-2])), radius, pred_colors[j], thickness)\n","            out_img = cv2.circle(out_img, (int(ball.x_trajectory[-1]), int(ball.y_trajectory[-1])), radius, colors[j], thickness)\n","            \n","    cv2.imwrite(\"./results_double/res_frame%d.jpg\" % i, out_img)"],"metadata":{"id":"ktzYSN3YxQKI","executionInfo":{"status":"aborted","timestamp":1670091875370,"user_tz":300,"elapsed":3833,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(1,3, figsize=(25,5))\n","\n","axs[0].plot(range(len(objects[0].probabilities)), objects[0].probabilities, label='ball 1')\n","axs[0].plot(range(len(objects[1].probabilities)), objects[1].probabilities, label='ball 2')\n","axs[0].set_xlabel('frame')\n","axs[0].set_ylabel('confidence of detection')\n","axs[0].set_title('Detection Confidence')\n","axs[0].legend()\n","\n","axs[1].plot(range(len(objects[0].x_trajectory)), objects[0].x_trajectory, label='detected + Kalman')\n","axs[1].plot(range(len(objects[0].x_predictions)), objects[0].x_predictions, label='Kalman prediction')\n","axs[1].set_xlabel('frame')\n","axs[1].set_ylabel('x-position')\n","axs[1].set_title('Ball 1')\n","axs[1].legend()\n","\n","axs[2].plot(range(len(objects[1].x_trajectory)), objects[1].x_trajectory, label='detected + Kalman')\n","axs[2].plot(range(len(objects[1].x_predictions)), objects[1].x_predictions, label='Kalman prediction')\n","axs[2].set_xlabel('frame')\n","axs[2].set_ylabel('x-position')\n","axs[2].set_title('Ball 2')\n","axs[2].legend()\n","\n","plt.show()"],"metadata":{"id":"IeVsNK_YTzdn","executionInfo":{"status":"aborted","timestamp":1670091875371,"user_tz":300,"elapsed":3830,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Save Video"],"metadata":{"id":"Ko_zaI7xZSLQ"}},{"cell_type":"code","source":["# https://stackoverflow.com/questions/57377185/how-play-mp4-video-in-google-colab\n","frame = cv2.imread(\"./results_double/res_frame0.jpg\")\n","height, width, layers = frame.shape\n","fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n","video = cv2.VideoWriter('ball2_tracking.mp4', fourcc, 30, (width,height))\n","\n","for i in range(num_frames):\n","    img = cv2.imread(\"./results_double/res_frame%d.jpg\" % i)\n","    video.write(img)\n","    \n","cv2.destroyAllWindows()\n","video.release()"],"metadata":{"id":"nrT4mT7BWTEJ","executionInfo":{"status":"aborted","timestamp":1670091875371,"user_tz":300,"elapsed":3829,"user":{"displayName":"Anshul Agrawal","userId":"12267851309340067408"}}},"execution_count":null,"outputs":[]}]}