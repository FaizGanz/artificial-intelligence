{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53ZwO7dzC8kj"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pantelis-nlp/tutorial-nlp-notebooks/blob/main/rnn_language_model.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN for Next Character Prediction"
      ],
      "metadata": {
        "id": "ZGrOvo2xkTD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of the model is to train a simple RNN for next character prediction. The model is trained by unrolling it over a sequences of 25 characters sampled from a source text, and at each time step it attempts to predict what the next character should be. Hence, for any given character, the model should output the next character in the text given its current hidden state. We can use such model, for example, to generate a sequence of character of specified length, as we will see later.\n",
        "\n",
        "In the following cell, we take in a text sample, this will serve us as dataset. Our vocabulary will be the set of all characters contained in the sample. We save the size of this set as our vocabulary size. Out of the character set, we construct two dictionaries to map character with indices and vice-versa. \n",
        "\n",
        "We declare the length of our window over which we will sample the input characters, the size of the the hidden state vector of the RNN, and our learning rate.\n",
        "\n",
        "The characters are passed passed through the model as one-hot encoded vector.\n",
        "The three RNN weight matrices are initialized with random numbers and the two bias vectors are inizialized with zeros. The first matrix (Wxh) maps the input x, of the size of the vocabulary, to a vector of the size of the hidden state. The second one (Whh) maps the hidden state vector to another vector of the same size. The last one (Why) maps a vector of the size of the hidden state to a vector of the size of the output vector y, which is the size of the vocabulary, given that we are trying to classify a character in our vocabulary.\n",
        "\n",
        "For the first two matrices Wxh and Whh, we declare a bias vector of the size of the hidden state. These three are used to calculate the value of the new hidden state. For matrix Why, we declare a bias of the size of the vocabulary, given that our ouput is of that size."
      ],
      "metadata": {
        "id": "gRXP_m6Fp9nT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaJ0WRAhG0cA"
      },
      "source": [
        "data = 'Chios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the length of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Provatas.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fAPuTnEF8Xj",
        "outputId": "fc34297d-6153-429f-b265-ab033f9f33c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# see here for notation http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture10.pdf\n",
        "\"\"\"\n",
        "Minimal character-level Vanilla RNN model. Written by Andrej Karpathy (@karpathy)\n",
        "BSD License\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "# data I/O\n",
        "#data = open('input.txt', 'r').read() # should be simple plain text file - you can use any (small) file in txt format from the web or type your own. \n",
        "\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "# hyperparameters\n",
        "hidden_size = 100 # size of hidden layer of neurons\n",
        "seq_length = 25 # number of steps to unroll the RNN for\n",
        "learning_rate = 1e-1\n",
        "\n",
        "# model parameters\n",
        "Wxh = np.random.randn(hidden_size, vocab_size)*0.01 # input to hidden\n",
        "Whh = np.random.randn(hidden_size, hidden_size)*0.01 # hidden to hidden\n",
        "Why = np.random.randn(vocab_size, hidden_size)*0.01 # hidden to output\n",
        "bh = np.zeros((hidden_size, 1)) # hidden bias\n",
        "by = np.zeros((vocab_size, 1)) # output bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 508 characters, 43 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sample function below, takes in an input character index (seed_ix) from which it will obtain the one-hot representation of that character and hidden state (h), and generates n characters by unrolling the model n times.\n",
        "For each step it computes the new hidden states, and the output y. The output y is of the size of the vocabulary and, when passed through a softmax function, it returns the probabilities of each characters in the vocabulary being the output character. We do not strictly take the character with the highest probability but we sample a character from this probability distribution, allowing us more flexibility in generating the text. We use the predicted character, as the input to our next RNN unroll, and we return all characters generated as a list of their corresponding indices in the vocabulary. This list, can then be mapped to the corresponding characters and concatenated to form our generated output text."
      ],
      "metadata": {
        "id": "1y-WzK9O-1N1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJM73XLoY0q3"
      },
      "source": [
        "def sample(h, seed_ix, n):\n",
        "  \"\"\" \n",
        "  sample a sequence of integers from the model \n",
        "  h is memory state, seed_ix is seed letter for first time step\n",
        "  \"\"\"\n",
        "  x = np.zeros((vocab_size, 1))\n",
        "  x[seed_ix] = 1\n",
        "  ixes = []\n",
        "  for t in range(n):\n",
        "    h = np.tanh(np.dot(Wxh, x) + np.dot(Whh, h) + bh) # compute new hidden state h_t\n",
        "    y = np.dot(Why, h) + by # compute output at time step t\n",
        "    p = np.exp(y) / np.sum(np.exp(y)) # Softmax of the output y\n",
        "    ix = np.random.choice(range(vocab_size), p=p.ravel())\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    x[ix] = 1\n",
        "    ixes.append(ix)\n",
        "  return ixes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function\n",
        "\n",
        "In the loss function below, we train our model parameters on a specific sequence of characters and we return the gradients of all parameters together with the cross entropy loss.\n",
        "\n",
        "Forward Pass:\n",
        "\n",
        "In the forward pass for the loss function, we iterate through the characters of the input sequence. At each time step, we encode the character as a one hot vector and feed it to the RNN. Through this input and the previous hidden state we compute the hidden state update $h_t = tanh(W_{xh}x_t + W_{hh}h_{t-1} +b_h)$ and the output $y_t=W_{hy}h_t +b_y$. We then compute the probability distribution over the classes (characther index) through the softmax function and finally, we compute the cross-entropy loss. We repeat this process for all characters in the input sequence.\n",
        "\n",
        "Backward Pass:\n",
        "\n",
        "In the backwards pass we iterate through the sequence backwards to compute the gradients. To handle the calculations, the values of the inputs, hidden states, outputs, and softmax values, is saved in a dictionary at each time step in the forward pass. The first two lines in the backprop loop portion of the code we compute the gradient of loss with respect to the output (dy), through eq. 10.18 (Goodfellow)\n",
        "\n",
        "$(\\nabla_{o^{(t)}}L)_i=\\hat{y}^{(t)}-1_{i,y^{(t)}}$\n",
        "\n",
        "In the next two lines, we update the derivative of $W_{hy}$ (dWhy) and $b_{y}$ (dby) through the equations 10.22 and 10.24 (Goodfellow)\n",
        "\n",
        "$\\nabla_V L = \\sum_t \\nabla_{o^{(t)}}L h_t^T$\n",
        "\n",
        "$\\nabla_c L = \\sum_t \\nabla_{o^{(t)}}L$\n",
        "\n",
        "We then compute the gradient with respect to the hidden state $h^{(t)}$ (dh) at time t. During our first backprop iteration there is no next hidden state therefore the value of the equation is\n",
        "\n",
        "$\\nabla_{h^{(t)}}L = W^T (\\nabla_{o^{(t)}}L)$ (eq. 10.19 Goodfellow)\n",
        "\n",
        "For the next steps of the back propagation we add the recursive derivative terms to the equation, which results in\n",
        "\n",
        "$\\nabla_{h^{(t)}}L = W^T diag(1-(h^{(t+1)})^2)(\\nabla_{h^{(t+1)}}L) + W\n",
        "^T (\\nabla_{o^{(t)}}L)$ (eq. 10.21 Goodfellow)\n",
        "\n",
        "The values of $W^T diag(1-(h^{(t+1)})^2)(\\nabla_{h^{(t+1)}}L)$ are calculate and updated through the variables\n",
        "\n",
        "dhraw $=diag(1-(h^{(t+1)})^2)(\\nabla_{h^{(t+1)}}L)$ \n",
        "\n",
        "dhnext $=W_{hh}^T dhraw$\n",
        "\n",
        "The dhraw variable, computed for the current hidden state, instead of the next one, is used to compute the derivatives of $b_y$ (db), $W_{hh}$ (dWhh), and $W_{xh}$ (dWxh), through equations 10.23, 10.26, 10.28 (Goodfellow)\n",
        "\n",
        "$\\nabla_b L = \\sum_{t}diag(1-(h^{(t)})^2)(\\nabla_{h^{(t)}}L)$\n",
        "\n",
        "$\\nabla_{W} L = \\sum_{t}diag(1-(h^{(t)})^2) (\\nabla_{h^{(t)}}L) {x^{(t)}}^T$\n",
        "\n",
        "$\\nabla_{U} L = \\sum_{t}diag(1-(h^{(t)})^2) (\\nabla_{h^{(t)}}L) {h^{(t-1)}}^T$\n",
        "\n",
        "At the end of the function we return the derivatives, which will be used in our training loop to update the parameters."
      ],
      "metadata": {
        "id": "mtdcVphADV-m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU236iBMYtWS"
      },
      "source": [
        "def lossFun(inputs, targets, hprev):\n",
        "  \"\"\"\n",
        "  inputs,targets are both list of integers.\n",
        "  hprev is Hx1 array of initial hidden state\n",
        "  returns the loss, gradients on model parameters, and last hidden state\n",
        "  \"\"\"\n",
        "\n",
        "  xs, hs, ys, ps = {}, {}, {}, {}\n",
        "  hs[-1] = np.copy(hprev)\n",
        "  loss = 0\n",
        "  # forward pass\n",
        "  for t in range(len(inputs)):\n",
        "    xs[t] = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
        "    xs[t][inputs[t]] = 1\n",
        "    hs[t] = np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh) # hidden state\n",
        "    ys[t] = np.dot(Why, hs[t]) + by # unnormalized log probabilities for next chars\n",
        "    ps[t] = np.exp(ys[t]) / np.sum(np.exp(ys[t])) # probabilities for next chars\n",
        "    loss += -np.log(ps[t][targets[t],0]) # softmax (cross-entropy loss)\n",
        "  # backward pass: compute gradients going backwards\n",
        "  dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "  dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
        "  dhnext = np.zeros_like(hs[0])\n",
        "  for t in reversed(range(len(inputs))):\n",
        "    dy = np.copy(ps[t])\n",
        "    dy[targets[t]] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here\n",
        "    dWhy += np.dot(dy, hs[t].T)\n",
        "    dby += dy\n",
        "    dh = np.dot(Why.T, dy) + dhnext # backprop into h\n",
        "    dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity\n",
        "    dbh += dhraw\n",
        "    dWxh += np.dot(dhraw, xs[t].T)\n",
        "    dWhh += np.dot(dhraw, hs[t-1].T)\n",
        "    dhnext = np.dot(Whh.T, dhraw)\n",
        "  for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
        "  return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs)-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Testing the RNN"
      ],
      "metadata": {
        "id": "FtSPsxBNmfGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the training cell, we start by declaring two variables, n and p. The variable n keeps track of the training iteration, while p tracks the starting index of our window over the text data provided. We generate samples from the text by sliding this window by one character at each iteration.\n",
        "\n",
        "In our training loop, at the first iteration, we initialize the hidden state as a vector of zeros. We then sample portions of the text data starting from the beginning and looking at windows of size 25, shifting our window by 1 character at every iteration. This portion of our text, which will be the input to our model, is then converted from characters to indices with the help of the dictionaries previously declared. If the window reaches the end of the sentence, the index p is reset to 0, as well as the hidden state. The target of the input is the portion of the sample obtained by shifting the window over by 1 character, since the output of the model for each input character should be the next character in the sequence. The target sequences are also encoded from characters to indices. We then pass the input, targets, and current hidden state to the loss function which returns us the loss, the derivatives of the weights, and the updated hidden state which will be used to train the next sample. The weight matricies and bias vectors are then updated through the AdaGrad algorithm thanks to the derivatives calculated, improving the model performance. This process can be repeated for as many iteration as needed until the loss converges.\n",
        "\n",
        "Every 1000 training iteration, we test the model by providing it with the first character of the current input sequence, the current hidden state of the model, and the number of times we want to unroll the model. In our case it is set to 200, meaning the model will produce 200 character that it thinks will follow from the input character, given the current hidden state of the model. We will see that the model will gradually start generating better and better sequences of characters the more training iteration it goes through. However, we can also notice that the more we train the model, the more it start overfitting the dataset, which causes it to produce only sentences that are very similare to the input text which we provide it. To generate more text more robustly, we would need a lot more training data, and a much bigger model."
      ],
      "metadata": {
        "id": "fW3gw5e1upYa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkOdfAJPY81L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "448e58f1-7b96-47e8-efd3-05f5daf70dcb"
      },
      "source": [
        "n, p = 0, 0\n",
        "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
        "smooth_loss = -np.log(1.0/vocab_size)*seq_length # loss at iteration 0\n",
        "\n",
        "while n <= 25000:\n",
        "  # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
        "  if p+seq_length+1 >= len(data) or n == 0: \n",
        "    hprev = np.zeros((hidden_size,1)) # reset RNN memory\n",
        "    p = 0 # go from start of data\n",
        "  inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
        "  targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
        "\n",
        "  # sample from the model now and then\n",
        "  if n % 1000 == 0:\n",
        "    sample_ix = sample(hprev, inputs[0], 200)\n",
        "    txt = ''.join(ix_to_char[ix] for ix in sample_ix)\n",
        "    print('----\\n %s \\n----' % (txt, ))\n",
        "\n",
        "  # forward seq_length characters through the net and fetch gradient\n",
        "  loss, dWxh, dWhh, dWhy, dbh, dby, hprev = lossFun(inputs, targets, hprev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "  if n % 1000 == 0: print('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
        "  \n",
        "  # perform parameter update with Adagrad\n",
        "  for param, dparam, mem in zip([Wxh, Whh, Why, bh, by], \n",
        "                                [dWxh, dWhh, dWhy, dbh, dby], \n",
        "                                [mWxh, mWhh, mWhy, mbh, mby]):\n",
        "    mem += dparam * dparam\n",
        "    param += -learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
        "\n",
        "  p += seq_length # move data pointer\n",
        "  n += 1 # iteration counter "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----\n",
            " ]5l9Pdl3)n]Eawqit.t()pqf4hdf5.emdE7bCTs.2[c4.,[ itg8h3e93bqt1reiC0aP)rrto,sP75P wt q,h41)uamas)p21,s15n4a1n3bCw180[nyEyp)s.s.imrmT,t,oeq.r]P4toEh3m8Ps5nk [k9348mi3hpe9s5ugqbhm4n,r5p489(2,0C(d.npc).qst \n",
            "----\n",
            "iter 0, loss: 94.029999\n",
            "----\n",
            " hios oshe nnd, Perween pis ritwath wrheon aoown, ay a r0t ot d,e, ne ne rtee the s (1 wn, (4, 5T8by a loss, 9erthlam Peindn 9hi pon and apes Prt1 fe  asdtheras and y m (3,8m8 ftwien easl sidna oun tu  \n",
            "----\n",
            "iter 1000, loss: 64.996564\n",
            "----\n",
            " hid arlert an lars, (321,.[5] mobnt int,,. m liof kiot ors arlaid Pe(3m wslery th toasia oe Theid irlanins,, Then lof se) cem (ranped Pe soan loutlan lof ti) te nte the thon tou souniou twanila yof la \n",
            "----\n",
            "iter 2000, loss: 35.330101\n",
            "----\n",
            " hiors and rr kid, aons angeas The thit of s8and is crenor (r, mousland wistaerisatland, a liny a tha ing soum inithe nous fidperlane s wered, dive of twand is (1,18257 mklelft) f er ing ar i) at aris  \n",
            "----\n",
            "iter 3000, loss: 26.437240\n",
            "----\n",
            " hios islant is crescethe rocrlang sh teridland is the lens, The two laperth of these mountar rainnis aroutport. 81 intais mouthe anrw rretlend insd ent island, Peog tedinecr kcethe rounnd islong ort a \n",
            "----\n",
            "iter 4000, loss: 13.113043\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long frratge of the island perraino sst noland is dr, and The cedn wider2,atg ft) anoft ar and west by a range ng shascenitwd byd Epos (1,188 m  \n",
            "----\n",
            "iter 5000, loss: 6.300943\n",
            "----\n",
            " hirs aknidge of mountains running the length of the island is divided between east angpea dhe in th wn ns km kn ano The two largest of these mountains, Pelineon (1,297 m (4,255 ft)apd er kinn rr andth \n",
            "----\n",
            "iter 6000, loss: 3.234717\n",
            "----\n",
            " hious and arid, widea long corth, rangth of tpesid (31 8.259 k1,, (32 (4m bgtwerid andpere nd Prid, with a ridge d, The two uated is ft). rginte ri), and Eeof corthe island. The in the north of the is \n",
            "----\n",
            "iter 7000, loss: 1.849456\n",
            "----\n",
            " hios islapth aing ao shcennd. The center of the island is divided between east and west belaent or kid.[2] The terrain is mountainounk, st) at its widest, civerinrran ar aprin (18 mi) ning ated island \n",
            "----\n",
            "iter 8000, loss: 3.108445\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar \n",
            "----\n",
            "iter 9000, loss: 1.654817\n",
            "----\n",
            " hios island is crescinn an ar in the north of the island. The center of the island. The two larm kre st of these molnteate widge of mountains running the length of the island is divided between east a \n",
            "----\n",
            "iter 10000, loss: 1.001365\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north to soft), rgesthe rge lor tength of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,18 \n",
            "----\n",
            "iter 11000, loss: 0.702052\n",
            "----\n",
            " wios island is crescent oro mountwinge south, dnd 29 km (18 mi) atland iy divided between east and west by a range of smaller peaks, known as Pne shateats, Penid draped, 50 km (31 mi) long from north  \n",
            "----\n",
            "iter 12000, loss: 2.135974\n",
            "----\n",
            " hios island is crescent or kidney shapeas Prand in area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the bent, Pelineon (1,897 m c4vi)ed Ef \n",
            "----\n",
            "iter 13000, loss: 1.132397\n",
            "----\n",
            " hios island is crescent or kidnend iThe at a range of she island. T0 kiuut ins, Pelineon (1,297 m (4,255 ft)) and Epos (1,18297 m (4,255 25.215 m (4,255 ft)) and aris, (318210 she the or kidney shaped \n",
            "----\n",
            "iter 14000, loss: 0.712292\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north te is 29 km (18 mi) at its widest, coverm and aen di kee siunte ngeasth aing of the island is divided between east and west by a \n",
            "----\n",
            "iter 15000, loss: 0.531333\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) anout and arid, with a ridge of mountains running the length of the island. The two largest of these mountainsa with anod int centeral, (1 2Th g \n",
            "----\n",
            "iter 16000, loss: 0.444045\n",
            "----\n",
            " hios island is creslane is crescent or kidney shaped, 50 km (31 mie is and is dpe isuthe north of the island. The center of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft) \n",
            "----\n",
            "iter 17000, loss: 0.922058\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar \n",
            "----\n",
            "iter 18000, loss: 0.604279\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (328d and m0 kit, sountain is mountainous and arid, with a ridge of mountains running the length of the island. The two largest of these mountains, Peli \n",
            "----\n",
            "iter 19000, loss: 0.448384\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar \n",
            "----\n",
            "iter 20000, loss: 0.367713\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (3,898 ft)), are sislaresth ora inge of mount) erthean area oof the island, The two largerinnd ard widest, covering ino st km ering an area of 842.289 k \n",
            "----\n",
            "iter 21000, loss: 0.322961\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar \n",
            "----\n",
            "iter 22000, loss: 0.292694\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar \n",
            "----\n",
            "iter 23000, loss: 0.294867\n",
            "----\n",
            " hios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and ar \n",
            "----\n",
            "iter 24000, loss: 0.279329\n",
            "----\n",
            " hiros (ou lins area iof the tweeithe north and, (18 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.28 m (18 mi) at its widest, covering an area of 842.289 km2 ( \n",
            "----\n",
            "iter 25000, loss: 0.239663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN for Next-Character Prediction"
      ],
      "metadata": {
        "id": "44VqloJIj30i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Afk8LNZf2C7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Processing"
      ],
      "metadata": {
        "id": "pvsf0pquKOiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = 'Chios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 842.289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of mountains running the length of the island. The two largest of these mountains, Pelineon (1,297 m (4,255 ft)) and Epos (1,188 m (3,898 ft)), are situated in the north of the island. The center of the island is divided between east and west by a range of smaller peaks, known as Provatas.'"
      ],
      "metadata": {
        "id": "FIdWKpobL2UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = list(set(sample_text))\n",
        "data_size, vocab_size = len(sample_text), len(chars)\n",
        "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIfEfuoZGYBb",
        "outputId": "65067c57-68ae-4103-a827-5e7f69b04cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data has 508 characters, 43 unique.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 25\n",
        "n_samples = len(sample_text) - seq_length\n",
        "\n",
        "# Generate Samples from Sample Text (sliding window size = 25)\n",
        "X = []\n",
        "y = []\n",
        "for i in range(n_samples):\n",
        "    sample = [char_to_ix[ch] for ch in sample_text[i : i + seq_length]]\n",
        "    target = char_to_ix[sample_text[i + seq_length]]\n",
        "    X += [sample]\n",
        "    y += [target]\n",
        "\n",
        "# Train Test Split\n",
        "training_size = int(0.9 * len(X))\n",
        "\n",
        "X_train = X[:training_size]\n",
        "y_train = y[:training_size]\n",
        "\n",
        "X_test = X[training_size:]\n",
        "y_test = y[training_size:]\n",
        "\n",
        "# One-hot Encoding\n",
        "X_train = F.one_hot(torch.tensor(X_train), num_classes=vocab_size)\n",
        "X_train = X_train.transpose(1, 2)\n",
        "\n",
        "X_test = F.one_hot(torch.tensor(X_test), num_classes=vocab_size)\n",
        "X_test = X_test.transpose(1, 2)\n",
        "\n",
        "y_train = torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)\n",
        "\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1CijnBgKLyV",
        "outputId": "397db7f0-8c01-412f-c993-216742d5ba51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([434, 43, 25]) torch.Size([49, 43, 25]) torch.Size([434]) torch.Size([49])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create PyTorch Dataset\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "l7nqfK4QNPGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Dataloader\n",
        "trainDataLoader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
        "testDataLoader = DataLoader(test_dataset,batch_size=1,shuffle=False)"
      ],
      "metadata": {
        "id": "W5EjZGkdRchR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Architecture"
      ],
      "metadata": {
        "id": "49McGhfrYgh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CharCNN(nn.Module):\n",
        "    def __init__(self, seq_length, vocab_size):\n",
        "        super(CharCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=vocab_size, out_channels=128, kernel_size=5, padding=2)\n",
        "        self.linear = nn.Linear(128, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool1d(x, kernel_size=seq_length).flatten(start_dim=1)\n",
        "        x = self.linear(x) \n",
        "        return x # No need to pass softmax, CE handles it with the max"
      ],
      "metadata": {
        "id": "Bu1laRE_UCdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CharCNN(seq_length=seq_length, vocab_size=vocab_size)"
      ],
      "metadata": {
        "id": "Bz33fF-nenZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, (vocab_size, seq_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7z6b3RIad34",
        "outputId": "0809f267-faae-4b6e-f38e-2814d2e88698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1              [-1, 128, 25]          27,648\n",
            "            Linear-2                   [-1, 43]           5,547\n",
            "================================================================\n",
            "Total params: 33,195\n",
            "Trainable params: 33,195\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 0.13\n",
            "Estimated Total Size (MB): 0.16\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss, Optimizer, and Scheduler"
      ],
      "metadata": {
        "id": "IQv13-_eudB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "lr = 0.1\n",
        "momentum = 0.9\n",
        "milestones = [35, 45]  \n",
        "gamma = 0.1\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=gamma) # decresing lr by a factor of gamma at each milestone"
      ],
      "metadata": {
        "id": "YNkbBD6h5kNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Model"
      ],
      "metadata": {
        "id": "I4IgoQH885uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "train_acc_history = []\n",
        "test_acc_history = []\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = 0.0\n",
        "    test_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "    for i, data in enumerate(trainDataLoader):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs.float())\n",
        "        _, predictions = torch.max(output, 1)\n",
        "        fit = criterion(output,labels)\n",
        "        fit.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += fit.item()\n",
        "        train_acc += torch.sum(predictions == labels.data)\n",
        "\n",
        "    model.eval()\n",
        "    for i, data in enumerate(testDataLoader):\n",
        "        with torch.no_grad():\n",
        "            inputs, labels = data\n",
        "            output = model(inputs.float())\n",
        "            _, predictions = torch.max(output, 1)\n",
        "            fit = criterion(output,labels)\n",
        "            test_loss += fit.item()\n",
        "            test_acc += torch.sum(predictions == labels.data)\n",
        "\n",
        "    scheduler.step()\n",
        "    \n",
        "    train_acc = (train_acc.float() / len(trainDataLoader.dataset)).item()\n",
        "    test_acc = (test_acc.float() / len(testDataLoader.dataset)).item()\n",
        "    train_acc_history += [train_acc]\n",
        "    test_acc_history += [test_acc]\n",
        "\n",
        "    train_loss = train_loss/len(trainDataLoader)\n",
        "    test_loss = test_loss/len(testDataLoader)\n",
        "    train_loss_history += [train_loss]\n",
        "    test_loss_history += [test_loss]\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print('Epoch %s, Train loss %s, Test loss %s, Train acc %s, Test acc %s'%(epoch, train_loss, test_loss, train_acc, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owWW9Mr059D1",
        "outputId": "7a633d5a-af10-4663-bebe-06b97fc192b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train loss 3.005699021475656, Test loss 3.245922881729749, Train acc 0.18433180451393127, Test acc 0.18367347121238708\n",
            "Epoch 10, Train loss 2.607136913708278, Test loss 3.2114069023910834, Train acc 0.2142857164144516, Test acc 0.18367347121238708\n",
            "Epoch 15, Train loss 2.1507206644330705, Test loss 3.7507688780220185, Train acc 0.3041474521160126, Test acc 0.18367347121238708\n",
            "Epoch 20, Train loss 1.8319541726793562, Test loss 3.820163988337225, Train acc 0.4124423861503601, Test acc 0.18367347121238708\n",
            "Epoch 25, Train loss 1.1929408482142858, Test loss 3.9778963777483725, Train acc 0.6105991005897522, Test acc 0.20408163964748383\n",
            "Epoch 30, Train loss 0.8133836218288967, Test loss 5.069316960377049, Train acc 0.7811059951782227, Test acc 0.18367347121238708\n",
            "Epoch 35, Train loss 0.5161472686699459, Test loss 5.4633922067908, Train acc 0.8548387289047241, Test acc 0.18367347121238708\n",
            "Epoch 40, Train loss 0.25359049439430237, Test loss 5.893345626755332, Train acc 0.9953917264938354, Test acc 0.18367347121238708\n",
            "Epoch 45, Train loss 0.2263396829366684, Test loss 5.979209894048316, Train acc 0.9953917264938354, Test acc 0.18367347121238708\n",
            "Epoch 50, Train loss 0.22150683509452002, Test loss 5.969410904977774, Train acc 0.9953917264938354, Test acc 0.18367347121238708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reached 100% training accuracy but test accuracy remains very low. We could have trained for less, but wanted to show that the model has fully memorized the data in the next cell, when we generate the text. Again, given the very small amount of data we are training and the limited scale of the model, the performance on unseen data is very low and does not improve the more we train our model. It actually gets worse. So, just as saud before for the RNN, we would need a lot more training data and a bigger model to improve the performance."
      ],
      "metadata": {
        "id": "Cz03rV0zFvxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_loss_history)\n",
        "plt.plot(test_loss_history)\n",
        "plt.legend([\"train\", \"val\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yzdYz6l8HQn8",
        "outputId": "5f0c8bd1-26e9-466b-f9cf-86b46938bb2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_acc_history)\n",
        "plt.plot(test_acc_history)\n",
        "plt.legend([\"train\", \"val\"])\n",
        "plt.title(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "bvTYV3mwHfbO",
        "outputId": "c30bcc4b-139d-405e-c366-77a576aee6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate Next 200 Characters from Input Sequence of 25 Characters"
      ],
      "metadata": {
        "id": "ygbm8INu9AdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(test_sample, n):\n",
        "    input_text = test_sample\n",
        "    generated_text = ''\n",
        "    with torch.no_grad():\n",
        "        for i in range(n):\n",
        "            x_test = torch.tensor([[char_to_ix[ch] for ch in input_text]])\n",
        "            x_test = F.one_hot(x_test, num_classes=vocab_size)\n",
        "            x_test = x_test.transpose(1, 2)\n",
        "            output = model(x_test.float())\n",
        "            _, predictions = torch.max(output, 1)\n",
        "            char_pred = ix_to_char[predictions[0].item()]\n",
        "            generated_text += char_pred\n",
        "            input_text = input_text[1:] + char_pred\n",
        "\n",
        "    return test_sample + generated_text"
      ],
      "metadata": {
        "id": "i2iH9KhKvQ1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample = 'she walked down the steps'\n",
        "print(generate_text(test_sample, 200))\n",
        "\n",
        "test_sample = 'Chios island is crescent ' \n",
        "print(generate_text(test_sample, 200))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK9XmcvxvtQA",
        "outputId": "f2c9acc0-1c02-4efb-8bf0-a5d7d0c039ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "she walked down the steps          r o ii d a d oes aod kides  os  ,      ,, an eao id add sif to ir o s oe ess and wekik wiee (th of thes sand seesi ei e ioo  rok ksnnn nnns h h he moes rrirs rrano iountain  n  ng the srrnae\n",
            "Chios island is crescent or kidney shaped, 50 km (31 mi) long from north to south, and 29 km (18 mi) at its widest, covering an area of 8422289 km2 (325.210 sq mi).[2] The terrain is mountainous and arid, with a ridge of moun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our model has fully memorized the training data, and if given the exact first 25 characters of the text sample it will generate the rest on its own. However, it generalizes poorly on unseen data, and is capable of producing very few word from english, the rest being just gibberish."
      ],
      "metadata": {
        "id": "7tyr_YZ3EvxV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rjNDtB7eFsZS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}